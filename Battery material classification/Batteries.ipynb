{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":925041,"sourceType":"datasetVersion","datasetId":498795}],"dockerImageVersionId":30527,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparation\n\nThe goal of this case study is to classify the data provided using logistic regression, decision tree, random forest and extra random forest. The resulting classified data will then be compared through the classification report, confusion matrix, accuracy score, and if applicable, roc_auc_score.","metadata":{}},{"cell_type":"markdown","source":"Let's import the required libraries first.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:24:04.354075Z","iopub.execute_input":"2023-08-26T06:24:04.354652Z","iopub.status.idle":"2023-08-26T06:24:05.065437Z","shell.execute_reply.started":"2023-08-26T06:24:04.354619Z","shell.execute_reply":"2023-08-26T06:24:05.06459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/crystal-system-properties-for-liion-batteries/lithium-ion batteries.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:24:41.888877Z","iopub.execute_input":"2023-08-26T06:24:41.889234Z","iopub.status.idle":"2023-08-26T06:24:41.928868Z","shell.execute_reply.started":"2023-08-26T06:24:41.889207Z","shell.execute_reply":"2023-08-26T06:24:41.928219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:24:51.782251Z","iopub.execute_input":"2023-08-26T06:24:51.782712Z","iopub.status.idle":"2023-08-26T06:24:51.804211Z","shell.execute_reply.started":"2023-08-26T06:24:51.782686Z","shell.execute_reply":"2023-08-26T06:24:51.803206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To prepare the dataset, missing data is visually checked by using a heatmap available through the Seaborn library. ","metadata":{}},{"cell_type":"code","source":"sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:25:00.429175Z","iopub.execute_input":"2023-08-26T06:25:00.429579Z","iopub.status.idle":"2023-08-26T06:25:00.688704Z","shell.execute_reply.started":"2023-08-26T06:25:00.429547Z","shell.execute_reply":"2023-08-26T06:25:00.687778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generate and check the pairplot of the dataframe.","metadata":{}},{"cell_type":"code","source":"sns.pairplot(df,hue='Crystal System',palette='Set2')","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:25:27.313349Z","iopub.execute_input":"2023-08-26T06:25:27.314112Z","iopub.status.idle":"2023-08-26T06:25:47.650616Z","shell.execute_reply.started":"2023-08-26T06:25:27.314077Z","shell.execute_reply":"2023-08-26T06:25:47.649677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The use of the pairplot shows the relationship of each variable to the Crystal Systems of Li-ion batteries. With this, regression analysis is used wherein the variables Nsites and Volume showed an upward trend of regression. ","metadata":{}},{"cell_type":"markdown","source":"Columns with variables not needed in building models such as materials id, formula, and space group are removed to clean the dataset.","metadata":{}},{"cell_type":"code","source":"df.drop(['Materials Id','Formula','Spacegroup'],\n        axis=1,inplace=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:26:06.8499Z","iopub.execute_input":"2023-08-26T06:26:06.850278Z","iopub.status.idle":"2023-08-26T06:26:06.865903Z","shell.execute_reply.started":"2023-08-26T06:26:06.850229Z","shell.execute_reply":"2023-08-26T06:26:06.864963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(inplace=True)\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:26:13.335657Z","iopub.execute_input":"2023-08-26T06:26:13.336012Z","iopub.status.idle":"2023-08-26T06:26:13.349365Z","shell.execute_reply.started":"2023-08-26T06:26:13.335987Z","shell.execute_reply":"2023-08-26T06:26:13.348333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generate a frequency distribution of the Crystal Systems and whether or not it has a bandstructure.","metadata":{}},{"cell_type":"code","source":"sns.set_style('whitegrid')\nsns.countplot(x='Crystal System',\n              data=df,palette='RdBu_r')\n","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:26:22.740431Z","iopub.execute_input":"2023-08-26T06:26:22.74078Z","iopub.status.idle":"2023-08-26T06:26:22.947413Z","shell.execute_reply.started":"2023-08-26T06:26:22.740755Z","shell.execute_reply":"2023-08-26T06:26:22.946475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_style('whitegrid')\nsns.countplot(x='Crystal System',hue='Has Bandstructure',data=df,palette='RdBu_r')","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:27:19.443373Z","iopub.execute_input":"2023-08-26T06:27:19.443742Z","iopub.status.idle":"2023-08-26T06:27:19.686181Z","shell.execute_reply.started":"2023-08-26T06:27:19.443713Z","shell.execute_reply":"2023-08-26T06:27:19.6853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Logistic Regression\nLogistic Regression is used when the dependent variable or target is categorical. There are different types of logistic regression such as binary, multinomial, and \nordinal (Swaminathan, 2018). Binary logistic regression is used when the categorical response has only two possible outcomes. Multinomial logistic regression is used when \nthere are three or more categories used without ordering. Ordinal logistic regression is used when there are three or more categories with ordering. ","metadata":{}},{"cell_type":"markdown","source":"Build a Logistic Regression model. Split the data into a training set and a test set.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\nX_train, X_test, y_train, y_test = train_test_split(df.drop('Crystal System',axis=1), \n                                                    df['Crystal System'], test_size=0.30, \n                                                    random_state=101)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:27:59.334475Z","iopub.execute_input":"2023-08-26T06:27:59.334863Z","iopub.status.idle":"2023-08-26T06:27:59.560656Z","shell.execute_reply.started":"2023-08-26T06:27:59.334832Z","shell.execute_reply":"2023-08-26T06:27:59.559943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The test size is set to 30 leaving the training set to be at 70. Random state is set to 101.","metadata":{}},{"cell_type":"markdown","source":"Train the model.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlogmodel = LogisticRegression()\nlogmodel.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:28:11.142082Z","iopub.execute_input":"2023-08-26T06:28:11.142703Z","iopub.status.idle":"2023-08-26T06:28:11.185733Z","shell.execute_reply.started":"2023-08-26T06:28:11.142667Z","shell.execute_reply":"2023-08-26T06:28:11.185072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predict the values for the testing data and print a classification report to obtain the precision, recall and f1-score.","metadata":{}},{"cell_type":"code","source":"lr_predictions = logmodel.predict(X_test)\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test,lr_predictions))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:28:26.441836Z","iopub.execute_input":"2023-08-26T06:28:26.442207Z","iopub.status.idle":"2023-08-26T06:28:26.462916Z","shell.execute_reply.started":"2023-08-26T06:28:26.44218Z","shell.execute_reply":"2023-08-26T06:28:26.461733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Print the accuracy score.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\nprint(accuracy_score(y_test, lr_predictions))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:28:31.652984Z","iopub.execute_input":"2023-08-26T06:28:31.653806Z","iopub.status.idle":"2023-08-26T06:28:31.659971Z","shell.execute_reply.started":"2023-08-26T06:28:31.653771Z","shell.execute_reply":"2023-08-26T06:28:31.659314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Show the confusion matrix of the prediction.","metadata":{}},{"cell_type":"code","source":"confusion_matrix(y_test, lr_predictions)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:28:47.598451Z","iopub.execute_input":"2023-08-26T06:28:47.598835Z","iopub.status.idle":"2023-08-26T06:28:47.6062Z","shell.execute_reply.started":"2023-08-26T06:28:47.598804Z","shell.execute_reply":"2023-08-26T06:28:47.605621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = confusion_matrix(y_test, lr_predictions)\ndf_cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(lr_predictions))\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16})","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:29:16.660505Z","iopub.execute_input":"2023-08-26T06:29:16.660899Z","iopub.status.idle":"2023-08-26T06:29:17.00125Z","shell.execute_reply.started":"2023-08-26T06:29:16.660867Z","shell.execute_reply":"2023-08-26T06:29:17.000174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The values of precision, recall, and f1 score are obtained through a classification report. Output shows the precision, recall, and f1 score for the Crystal Systems \nof Li-ion batteries as well as its accuracy score. The confusion matrix of the prediction is shown which can be used to solve the precision, recall, f1 score, and accuracy mathematically.","metadata":{}},{"cell_type":"markdown","source":"# Decision Tree\n\nDecision Tree can be used to represent decisions and decision making visually and explicitly (Gupta, 2017). The name is taken from the tree-like model of decisions; \nhowever, the root is at the very top. The root is split into two decisions or leaves depending on the condition or internal node. In general, Decision Tree algorithms are \nreferred to as Classification and Regression Trees (CART).\n\nBuild the Decision Tree model and split the data into a training set and test set.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df.drop('Crystal System',axis=1)\ny = df['Crystal System']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:29:53.363855Z","iopub.execute_input":"2023-08-26T06:29:53.36424Z","iopub.status.idle":"2023-08-26T06:29:53.371483Z","shell.execute_reply.started":"2023-08-26T06:29:53.364209Z","shell.execute_reply":"2023-08-26T06:29:53.370614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The test size is set to 30 leaving the train set at 70. ","metadata":{}},{"cell_type":"markdown","source":"Train the model.","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndtree = DecisionTreeClassifier()\ndtree.fit(X_train,y_train)\n\ndtree.tree_.node_count, dtree.tree_.max_depth","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:30:03.710444Z","iopub.execute_input":"2023-08-26T06:30:03.711365Z","iopub.status.idle":"2023-08-26T06:30:03.85452Z","shell.execute_reply.started":"2023-08-26T06:30:03.711334Z","shell.execute_reply":"2023-08-26T06:30:03.853579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Decision Tree Classifier is used to obtain the count of nodes and maximum depth of the decision tree. ","metadata":{}},{"cell_type":"markdown","source":"Predict the values for the testing data and generate the classification report to check the precision, recall and f1-score.","metadata":{}},{"cell_type":"code","source":"dt_predictions = dtree.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:30:14.131067Z","iopub.execute_input":"2023-08-26T06:30:14.131526Z","iopub.status.idle":"2023-08-26T06:30:14.137922Z","shell.execute_reply.started":"2023-08-26T06:30:14.131495Z","shell.execute_reply":"2023-08-26T06:30:14.137083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n\nprint(classification_report(y_test,dt_predictions))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:30:17.481331Z","iopub.execute_input":"2023-08-26T06:30:17.481874Z","iopub.status.idle":"2023-08-26T06:30:17.50248Z","shell.execute_reply.started":"2023-08-26T06:30:17.481833Z","shell.execute_reply":"2023-08-26T06:30:17.501315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generate the confusion matrix and the accuracy score of the prediction.","metadata":{}},{"cell_type":"code","source":"print(confusion_matrix(y_test,dt_predictions))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:30:31.990824Z","iopub.execute_input":"2023-08-26T06:30:31.991501Z","iopub.status.idle":"2023-08-26T06:30:31.998475Z","shell.execute_reply.started":"2023-08-26T06:30:31.991463Z","shell.execute_reply":"2023-08-26T06:30:31.99742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image  \nfrom six import StringIO  \nfrom sklearn.tree import export_graphviz\nimport pydot \n\nfeatures = list(df.columns[1:])\nfeatures","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:30:42.100677Z","iopub.execute_input":"2023-08-26T06:30:42.101049Z","iopub.status.idle":"2023-08-26T06:30:42.113449Z","shell.execute_reply.started":"2023-08-26T06:30:42.101018Z","shell.execute_reply":"2023-08-26T06:30:42.112428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install Graphviz","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:34:30.86403Z","iopub.execute_input":"2023-08-26T06:34:30.864439Z","iopub.status.idle":"2023-08-26T06:34:42.672606Z","shell.execute_reply.started":"2023-08-26T06:34:30.864406Z","shell.execute_reply":"2023-08-26T06:34:42.671606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pydotplus","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:34:50.439198Z","iopub.execute_input":"2023-08-26T06:34:50.439596Z","iopub.status.idle":"2023-08-26T06:35:03.517226Z","shell.execute_reply.started":"2023-08-26T06:34:50.439563Z","shell.execute_reply":"2023-08-26T06:35:03.51601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from io import StringIO\nfrom IPython.display import Image, display\nimport pydotplus\n\nfrom sklearn.tree import export_graphviz\ndot_data = StringIO()\n\nexport_graphviz(dtree, out_file=dot_data, feature_names=features,filled=True,rounded=True)\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n\n    # View the tree image\nfilename = 'Batteries.png'\ngraph.write_png(filename)\nimg = Image(filename=filename)\ndisplay(img)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:35:07.133189Z","iopub.execute_input":"2023-08-26T06:35:07.133607Z","iopub.status.idle":"2023-08-26T06:35:09.802227Z","shell.execute_reply.started":"2023-08-26T06:35:07.133573Z","shell.execute_reply":"2023-08-26T06:35:09.800683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we used GraphViz and pydotplus to visualize the count of nodes and maximum depth of the decision tree. ","metadata":{}},{"cell_type":"markdown","source":"The values of precision, recall, and f1 score are obtained through a classification report. Output shows the precision, recall, and f1 score for the Crystal Systems of \nLi-ion batteries as well as its accuracy score. The confusion matrix of the prediction is shown which can be used to solve the precision, recall, f1 score, and accuracy mathematically.","metadata":{}},{"cell_type":"markdown","source":"# Random Forest\n\nRandom Forest is a supervised learning algorithm. The forest the algorithm builds is an ensemble of decision trees, usually with the bagging method (Donges, 2020). \nBagging is a combination of learning models that increases the overall result. A random forest builds multiple decision trees and merges them together to get a \nmore accurate and stable prediction. It can be used for both classification and regression problems.\n\nBuild the Random Forest model and split the data into a training set and test set.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df.drop('Crystal System',axis=1)\ny = df['Crystal System']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:35:28.633885Z","iopub.execute_input":"2023-08-26T06:35:28.634285Z","iopub.status.idle":"2023-08-26T06:35:28.64286Z","shell.execute_reply.started":"2023-08-26T06:35:28.634242Z","shell.execute_reply":"2023-08-26T06:35:28.64214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train the random forest model and predict the class of the Crystal Systems.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(n_estimators=200)\nrfc.fit(X_train,y_train)\nrf_predictions = rfc.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:35:34.364575Z","iopub.execute_input":"2023-08-26T06:35:34.36517Z","iopub.status.idle":"2023-08-26T06:35:34.914071Z","shell.execute_reply.started":"2023-08-26T06:35:34.365135Z","shell.execute_reply":"2023-08-26T06:35:34.913333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The test size is set to 30 leaving the train set at 70. The Random Forest Classifier is imported from sklearn and the estimators are set to 200.\n","metadata":{}},{"cell_type":"markdown","source":"Generate a classification report to obtain the precision, recall and f1-score of the model.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix,accuracy_score, roc_auc_score\nprint(classification_report(y_test,rf_predictions))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:35:53.122015Z","iopub.execute_input":"2023-08-26T06:35:53.122395Z","iopub.status.idle":"2023-08-26T06:35:53.138437Z","shell.execute_reply.started":"2023-08-26T06:35:53.122366Z","shell.execute_reply":"2023-08-26T06:35:53.137311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generate the confusion matrix and the accuracy score of the model.","metadata":{}},{"cell_type":"code","source":"print(confusion_matrix(y_test,rf_predictions))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:36:16.838844Z","iopub.execute_input":"2023-08-26T06:36:16.839219Z","iopub.status.idle":"2023-08-26T06:36:16.846802Z","shell.execute_reply.started":"2023-08-26T06:36:16.839188Z","shell.execute_reply":"2023-08-26T06:36:16.845595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(accuracy_score(y_test, rf_predictions))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:36:21.924181Z","iopub.execute_input":"2023-08-26T06:36:21.925292Z","iopub.status.idle":"2023-08-26T06:36:21.930823Z","shell.execute_reply.started":"2023-08-26T06:36:21.925238Z","shell.execute_reply":"2023-08-26T06:36:21.929931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The values of precision, recall, and f1 score are obtained through a classification report. Output shows the precision, recall, and f1 score for the Crystal Systems of Li-ion batteries as well as its accuracy score. The confusion matrix of the prediction is shown which can be used to solve the precision, recall, f1 score, and \naccuracy mathematically.","metadata":{}},{"cell_type":"markdown","source":"# Extra Random Forest\nExtra Random Forest is like a random forest and is also known as Extremely Randomized Trees. In an extra random forest, the features and splits are selected at random and it is less computationally expensive than a random forest (Ceballos, 2019).\n\nDecision trees show high variance, random forests show medium variance and extra random forest show low variance. \n\nBuild the Extra Random Forest model and split the data into a training set and test set.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df.drop('Crystal System',axis=1)\ny = df['Crystal System']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:36:42.330656Z","iopub.execute_input":"2023-08-26T06:36:42.331479Z","iopub.status.idle":"2023-08-26T06:36:42.339013Z","shell.execute_reply.started":"2023-08-26T06:36:42.331441Z","shell.execute_reply":"2023-08-26T06:36:42.33806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nTrain the model and predict the values for the testing data.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\n\netc = ExtraTreesClassifier(n_estimators=200)\netc.fit(X_train,y_train)\nerf_predictions=etc.predict(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:37:05.336207Z","iopub.execute_input":"2023-08-26T06:37:05.33667Z","iopub.status.idle":"2023-08-26T06:37:05.669353Z","shell.execute_reply.started":"2023-08-26T06:37:05.336638Z","shell.execute_reply":"2023-08-26T06:37:05.668553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The test size is set to 30 leaving the train set at 70. The Extra Trees Classifier is imported from sklearn and the estimators are set to 200.","metadata":{}},{"cell_type":"markdown","source":"Generate the classification report to obtain the precision, recall and f1-score of the model.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix,accuracy_score, roc_auc_score\nprint(classification_report(y_test,erf_predictions))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:37:16.88772Z","iopub.execute_input":"2023-08-26T06:37:16.888053Z","iopub.status.idle":"2023-08-26T06:37:16.902901Z","shell.execute_reply.started":"2023-08-26T06:37:16.888027Z","shell.execute_reply":"2023-08-26T06:37:16.901856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nGenerate the confusion matrix and accuracy score of the model.","metadata":{}},{"cell_type":"code","source":"print(confusion_matrix(y_test,erf_predictions))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:37:34.85145Z","iopub.execute_input":"2023-08-26T06:37:34.85183Z","iopub.status.idle":"2023-08-26T06:37:34.858833Z","shell.execute_reply.started":"2023-08-26T06:37:34.851802Z","shell.execute_reply":"2023-08-26T06:37:34.857815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(accuracy_score(y_test, erf_predictions))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:37:39.220058Z","iopub.execute_input":"2023-08-26T06:37:39.220728Z","iopub.status.idle":"2023-08-26T06:37:39.226811Z","shell.execute_reply.started":"2023-08-26T06:37:39.220689Z","shell.execute_reply":"2023-08-26T06:37:39.225742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The values of precision, recall, and f1 score are obtained through a classification report. Output shows the precision, recall, and f1 score for the Crystal Systems \nof Li-ion batteries as well as its accuracy score. The confusion matrix of the prediction is shown which can be used to solve the precision, recall, f1 score, and accuracy mathematically.","metadata":{}},{"cell_type":"markdown","source":"# K Nearest Neighbors (KNN)\n\nKNN is a simple algorithm that stores all available cases and predict the numerical target based on a similarity measure (Muhajir, 2019).The objective of the support vector machine algorithm is to find a hyperplane in an N-dimensional space that \ndistinctly classifies the data points (Gandhi, 2018). To separate the two classes of data points, there are many possible hyperplanes that could be chosen. The goal is to \nfind a plane that has a maximum margin.\n\nBuild the K Nearest Neighbors model and split the data into a training set and test set.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:38:07.698995Z","iopub.execute_input":"2023-08-26T06:38:07.699348Z","iopub.status.idle":"2023-08-26T06:38:07.703162Z","shell.execute_reply.started":"2023-08-26T06:38:07.69932Z","shell.execute_reply":"2023-08-26T06:38:07.702312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:38:11.093761Z","iopub.execute_input":"2023-08-26T06:38:11.094389Z","iopub.status.idle":"2023-08-26T06:38:11.098579Z","shell.execute_reply.started":"2023-08-26T06:38:11.094356Z","shell.execute_reply":"2023-08-26T06:38:11.097768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler.fit(df.drop('Crystal System',axis=1))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:38:17.896192Z","iopub.execute_input":"2023-08-26T06:38:17.89685Z","iopub.status.idle":"2023-08-26T06:38:17.9076Z","shell.execute_reply.started":"2023-08-26T06:38:17.896815Z","shell.execute_reply":"2023-08-26T06:38:17.906799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaled_features = scaler.transform(df.drop('Crystal System',axis=1))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:38:22.093985Z","iopub.execute_input":"2023-08-26T06:38:22.094355Z","iopub.status.idle":"2023-08-26T06:38:22.102038Z","shell.execute_reply.started":"2023-08-26T06:38:22.094327Z","shell.execute_reply":"2023-08-26T06:38:22.101292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_feat = pd.DataFrame(scaled_features,columns=df.columns[:-1])\ndf_feat.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:38:26.683076Z","iopub.execute_input":"2023-08-26T06:38:26.683447Z","iopub.status.idle":"2023-08-26T06:38:26.698686Z","shell.execute_reply.started":"2023-08-26T06:38:26.683415Z","shell.execute_reply":"2023-08-26T06:38:26.697467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:38:32.16764Z","iopub.execute_input":"2023-08-26T06:38:32.168802Z","iopub.status.idle":"2023-08-26T06:38:32.173109Z","shell.execute_reply.started":"2023-08-26T06:38:32.168755Z","shell.execute_reply":"2023-08-26T06:38:32.172117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(scaled_features,df['Crystal System'],\n                                                    test_size=0.30)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:38:35.825939Z","iopub.execute_input":"2023-08-26T06:38:35.826311Z","iopub.status.idle":"2023-08-26T06:38:35.83243Z","shell.execute_reply.started":"2023-08-26T06:38:35.826253Z","shell.execute_reply":"2023-08-26T06:38:35.83133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:38:39.982187Z","iopub.execute_input":"2023-08-26T06:38:39.982589Z","iopub.status.idle":"2023-08-26T06:38:39.986789Z","shell.execute_reply.started":"2023-08-26T06:38:39.982558Z","shell.execute_reply":"2023-08-26T06:38:39.985746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:38:46.178152Z","iopub.execute_input":"2023-08-26T06:38:46.17925Z","iopub.status.idle":"2023-08-26T06:38:46.183848Z","shell.execute_reply.started":"2023-08-26T06:38:46.179214Z","shell.execute_reply":"2023-08-26T06:38:46.182548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:38:51.114981Z","iopub.execute_input":"2023-08-26T06:38:51.115391Z","iopub.status.idle":"2023-08-26T06:38:51.124605Z","shell.execute_reply.started":"2023-08-26T06:38:51.115357Z","shell.execute_reply":"2023-08-26T06:38:51.123465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = knn.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:38:56.40576Z","iopub.execute_input":"2023-08-26T06:38:56.406115Z","iopub.status.idle":"2023-08-26T06:38:56.419039Z","shell.execute_reply.started":"2023-08-26T06:38:56.406087Z","shell.execute_reply":"2023-08-26T06:38:56.418182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Evaluate the KNN model.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix, accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:39:13.99759Z","iopub.execute_input":"2023-08-26T06:39:13.998226Z","iopub.status.idle":"2023-08-26T06:39:14.002414Z","shell.execute_reply.started":"2023-08-26T06:39:13.998194Z","shell.execute_reply":"2023-08-26T06:39:14.00142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(y_test,pred))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:39:17.479982Z","iopub.execute_input":"2023-08-26T06:39:17.480357Z","iopub.status.idle":"2023-08-26T06:39:17.486623Z","shell.execute_reply.started":"2023-08-26T06:39:17.480329Z","shell.execute_reply":"2023-08-26T06:39:17.485981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,pred))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:39:31.962046Z","iopub.execute_input":"2023-08-26T06:39:31.962909Z","iopub.status.idle":"2023-08-26T06:39:31.977209Z","shell.execute_reply.started":"2023-08-26T06:39:31.962872Z","shell.execute_reply":"2023-08-26T06:39:31.976324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Choose a K value. Create a method to pick a good value of K.","metadata":{}},{"cell_type":"code","source":"error_rate = []\n\n\nfor i in range(1,40):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:39:36.380286Z","iopub.execute_input":"2023-08-26T06:39:36.380708Z","iopub.status.idle":"2023-08-26T06:39:36.61735Z","shell.execute_reply.started":"2023-08-26T06:39:36.38068Z","shell.execute_reply":"2023-08-26T06:39:36.616575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a visualization to compare the error rate and k value.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:39:47.607883Z","iopub.execute_input":"2023-08-26T06:39:47.608231Z","iopub.status.idle":"2023-08-26T06:39:48.076567Z","shell.execute_reply.started":"2023-08-26T06:39:47.608203Z","shell.execute_reply":"2023-08-26T06:39:48.075612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# K = 1\nknn = KNeighborsClassifier(n_neighbors=1)\n\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\n\nprint('WITH K=1')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:40:11.732201Z","iopub.execute_input":"2023-08-26T06:40:11.732695Z","iopub.status.idle":"2023-08-26T06:40:11.762181Z","shell.execute_reply.started":"2023-08-26T06:40:11.732656Z","shell.execute_reply":"2023-08-26T06:40:11.761205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#K = 23\nknn = KNeighborsClassifier(n_neighbors=23)\n\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\n\nprint('WITH K=23')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n')\nprint(classification_report(y_test,pred))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:40:22.182982Z","iopub.execute_input":"2023-08-26T06:40:22.183592Z","iopub.status.idle":"2023-08-26T06:40:22.208327Z","shell.execute_reply.started":"2023-08-26T06:40:22.183558Z","shell.execute_reply":"2023-08-26T06:40:22.207482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fit the K-nearest neighbors model again with n_neighbors=3 but this time use distance for the weights. Calculate the accuracy using the function you created above.","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=3, weights='distance')\n\nknn = knn.fit(X_train, y_train)\n\ny_pred = knn.predict(X_test)\n\nprint(accuracy_score(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:40:44.837088Z","iopub.execute_input":"2023-08-26T06:40:44.838169Z","iopub.status.idle":"2023-08-26T06:40:44.847407Z","shell.execute_reply.started":"2023-08-26T06:40:44.838131Z","shell.execute_reply":"2023-08-26T06:40:44.846393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fit another K-nearest neighbors model. This time use uniform weights but set the power parameter for the Minkowski distance metric to be 1 (p=1) i.e. Manhattan Distance.","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=5, p=1)\n\nknn = knn.fit(X_train, y_train)\n\ny_pred = knn.predict(X_test)\n\nprint(accuracy_score(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:41:04.594277Z","iopub.execute_input":"2023-08-26T06:41:04.595063Z","iopub.status.idle":"2023-08-26T06:41:04.610015Z","shell.execute_reply.started":"2023-08-26T06:41:04.595028Z","shell.execute_reply":"2023-08-26T06:41:04.608942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fit a K-nearest neighbors model using values of k (n_neighbors) ranging from 1 to 20. Use uniform weights (the default). The coefficient for the Minkowski distance (p) can be set to either 1 or 2--just be consistent. Store the accuracy and the value of k used from each of these fits in a list or dictionary. Plot (or view the table of) the accuracy vs k. What do you notice happens when k=1?","metadata":{}},{"cell_type":"code","source":"# Fit the K-nearest neighbors model with different values of k\n# Store the accuracy measurement for each k\n\nscore_list = list()\n\nfor k in range(1, 30):\n    \n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn = knn.fit(X_train, y_train)\n    \n    y_pred = knn.predict(X_test)\n    score = accuracy_score(y_test, y_pred)\n    \n    score_list.append((k, score))\n    \nscore_df = pd.DataFrame(score_list, columns=['k', 'accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:41:27.162055Z","iopub.execute_input":"2023-08-26T06:41:27.162407Z","iopub.status.idle":"2023-08-26T06:41:27.351421Z","shell.execute_reply.started":"2023-08-26T06:41:27.162379Z","shell.execute_reply":"2023-08-26T06:41:27.349974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_context('talk')\nsns.set_style('ticks')\nsns.set_palette('dark')\n\nax = score_df.set_index('k').plot()\n\nax.set(xlabel='k', ylabel='accuracy')\nax.set_xticks(range(1, 30));","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:41:32.173045Z","iopub.execute_input":"2023-08-26T06:41:32.174177Z","iopub.status.idle":"2023-08-26T06:41:32.586646Z","shell.execute_reply.started":"2023-08-26T06:41:32.174127Z","shell.execute_reply":"2023-08-26T06:41:32.585411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Support Vector Machines\nBuild the Support Vector Machines model and split the data into a training set and test set.","metadata":{}},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:42:08.327893Z","iopub.execute_input":"2023-08-26T06:42:08.328273Z","iopub.status.idle":"2023-08-26T06:42:08.347303Z","shell.execute_reply.started":"2023-08-26T06:42:08.328231Z","shell.execute_reply":"2023-08-26T06:42:08.346659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:42:11.133134Z","iopub.execute_input":"2023-08-26T06:42:11.133564Z","iopub.status.idle":"2023-08-26T06:42:11.160325Z","shell.execute_reply.started":"2023-08-26T06:42:11.133531Z","shell.execute_reply":"2023-08-26T06:42:11.159441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = (df['Crystal System'] == 'monoclinic').astype(int)\nfields = list(df.columns[:-1])\ncorrelations = df[fields].corrwith(y)\ncorrelations.sort_values(inplace=True)\ncorrelations","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:42:17.403092Z","iopub.execute_input":"2023-08-26T06:42:17.403456Z","iopub.status.idle":"2023-08-26T06:42:17.417684Z","shell.execute_reply.started":"2023-08-26T06:42:17.403424Z","shell.execute_reply":"2023-08-26T06:42:17.416633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a pairplot for the dataset.","metadata":{}},{"cell_type":"code","source":"sns.set_context('talk')\nsns.set_palette('Paired')\nsns.set_style('white')\n\nsns.pairplot(df, hue='Crystal System')","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:42:51.464809Z","iopub.execute_input":"2023-08-26T06:42:51.465557Z","iopub.status.idle":"2023-08-26T06:43:12.696508Z","shell.execute_reply.started":"2023-08-26T06:42:51.465521Z","shell.execute_reply":"2023-08-26T06:43:12.695269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a bar plot showing the correlations between each column and y","metadata":{}},{"cell_type":"code","source":"ax = correlations.plot(kind='bar')\nax.set(ylim=[-1, 1], ylabel='correlation');","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:43:17.838653Z","iopub.execute_input":"2023-08-26T06:43:17.839389Z","iopub.status.idle":"2023-08-26T06:43:18.18879Z","shell.execute_reply.started":"2023-08-26T06:43:17.83935Z","shell.execute_reply":"2023-08-26T06:43:18.187777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nfields = correlations.map(abs).sort_values().iloc[-2:].index\nprint(fields)\nX = df[fields]\nscaler = MinMaxScaler()\nX = scaler.fit_transform(X)\nX = pd.DataFrame(X, columns=['%s_scaled' % fld for fld in fields])\nprint(X.columns)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:43:25.089758Z","iopub.execute_input":"2023-08-26T06:43:25.090306Z","iopub.status.idle":"2023-08-26T06:43:25.101508Z","shell.execute_reply.started":"2023-08-26T06:43:25.090254Z","shell.execute_reply":"2023-08-26T06:43:25.10082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import LinearSVC\n\nLSVC = LinearSVC()\nLSVC.fit(X, y)\n\nX_color = X.sample(300, random_state=45)\ny_color = y.loc[X_color.index]\ny_color = y_color.map(lambda r: 'red' if r == 1 else 'yellow')\nax = plt.axes()\nax.scatter(\n    X_color.iloc[:, 0], X_color.iloc[:, 1],\n    color=y_color, alpha=1)\n# -----------\nx_axis, y_axis = np.arange(0, 1.005, .005), np.arange(0, 1.005, .005)\nxx, yy = np.meshgrid(x_axis, y_axis)\nxx_ravel = xx.ravel()\nyy_ravel = yy.ravel()\nX_grid = pd.DataFrame([xx_ravel, yy_ravel]).T\ny_grid_predictions = LSVC.predict(X_grid)\ny_grid_predictions = y_grid_predictions.reshape(xx.shape)\nax.contourf(xx, yy, y_grid_predictions, cmap=plt.cm.autumn_r, alpha=.3)\n# -----------\nax.set(\n    xlabel=fields[0],\n    ylabel=fields[1],\n    xlim=[0, 1],\n    ylim=[0, 1],\n    title='decision boundary for LinearSVC');","metadata":{"execution":{"iopub.status.busy":"2023-08-26T06:43:29.919306Z","iopub.execute_input":"2023-08-26T06:43:29.919974Z","iopub.status.idle":"2023-08-26T06:43:31.999462Z","shell.execute_reply.started":"2023-08-26T06:43:29.919941Z","shell.execute_reply":"2023-08-26T06:43:31.998498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\nSince there are three crystal systems that the Li-ion batteries can be categorized into, the problem has become a multiclass classification. A multiclass classification makes the assumption that each sample is assigned to one and only one label, therefore, the battery can either be monoclinic, orthorhombic or triclinic, but it cannot be both at the same time. The dataset is also imbalanced such that there are 139 monoclinic batteries, 128 orthorhombic batteries and 72 triclinic batteries giving a 41:38:21 ratio. Because the dataset is biased towards the monoclinic batteries, the model overfits on that class label and predicts it with high accuracy, leaving the orthorhombic class with medium accuracy and the triclinic class with the lowest accuracy.","metadata":{}},{"cell_type":"markdown","source":"Comparing the resulting accuracy, precision, recall and F1 score of the models, we could conclude that the random forest produced the best results, followed by the \nextra random forest, logistic regression, KNN, and the decision tree. This proves that while the decision trees produced the fastest results, it suffered from overfitting and the random forest algorithm which produced the slowest results did not suffer from overfitting by creating trees on random subsets.","metadata":{}},{"cell_type":"markdown","source":"# Recommendations\nBecause the dataset used for the classification problem was imbalanced, it is recommended to re-sample the dataset to make it balanced and standardized. By  sampling a balanced dataset, the resulting metrics would be improved.","metadata":{}},{"cell_type":"markdown","source":"# Referrences\n\nSwaminathan, S. (2018, March 15). Logistic Regression Detailed \nOverview. Retrieved from Towards Data Science: \nhttps://towardsdatascience.com/logistic-regression-detailed\u0002overview-46c4da4303b\n\nGupta, P. (2017, May 18). Decision Trees in Machine Learning. \nRetrieved from Towards Data Science : \nhttps://towardsdatascience.com/decision-trees-in-machine\u0002learning-641b9c4e8052\n\nDonges, N. (2020, September 3). A Complete Guide to the Random \nForest Algorithm. Retrieved from Built In: \nhttps://builtin.com/data-science/random-forest-algorithm\n\nCeballos, F. (2019, July 14). An intuitive explanation of random forest \nand extra trees classifiers. Retrieved from Towards Data \nScience: https://towardsdatascience.com/an-intuitive\u0002explanation-of-random-forest-and-extra-trees-classifiers\u00028507ac21d54b\n\nGandhi, R. (2018, May 27). Introduction to Machine Learning \nAlgorithms: Linear Regression. Retrieved from Towards \nData Science: https://towardsdatascience.com/introduction\u0002to-machine-learning-algorithms-linear-regression\u000214c4e325882a\n\nMuhajir, I. (2019, April 20). K-Neighbors Regression Analysis in Python. \nRetrieved from Analytics Vidhya: \nhttps://medium.com/analytics-vidhya/k-neighbors-regression\u0002analysis-in-python-61532d56d8e4","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}